{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e1e8700",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "## Exercise 1:\n",
    "\n",
    "Within your `codeup-data-science` directory, create a new repo named `spark-exercises`. This will be where you do your work for this module. Create a repository on GitHub with the same name, and link your local repository to GitHub.\n",
    "\n",
    "Save this work in your `spark-exercises` repo. Then add, commit, and push your changes.\n",
    "\n",
    "Create a jupyter notebook or python script named `spark101` for this exercise.\n",
    "\n",
    "Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- Create a dataframe with one column named `language`\n",
    "> Hint: Start with a pandas dataframe. Maybe use a dictionary?\n",
    "- View the schema of the dataframe\n",
    "- Output the shape of the dataframe\n",
    "- Show the first 5 records in the dataframe\n",
    "\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a88ea22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4b3f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language\n",
       "0          C#\n",
       "1  JavaScript\n",
       "2         C++\n",
       "3  JavaScript\n",
       "4        None"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df= pd.read_json('repo_readmes_10_feb_am.json')\n",
    "pandas_df = pandas_df.drop(columns = ['repo','readme_contents'])\n",
    "pandas_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a584cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4b05ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  language|\n",
      "+----------+\n",
      "|        C#|\n",
      "|JavaScript|\n",
      "|       C++|\n",
      "|JavaScript|\n",
      "|      null|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844a8af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebc842fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  180  x  1\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame shape: \", df.count(), \" x \", len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e1e41",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "## Exercise 2:\n",
    "\n",
    "Load the `mpg` dataset as a spark dataframe.\n",
    "\n",
    "a. Create 1 column of output that contains a message like the one below for each record:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "\n",
    "> Hint: You will need to concatenate values that already exist in the data with string literals\n",
    "\n",
    "b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "> Hint: Consider spark string methods and `when().otherwise()` chaining\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b333cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, sum, avg, min, max, count, mean\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcd3b7",
   "metadata": {},
   "source": [
    "## a. Create 1 column of output that contains a message like the one below for each record:\n",
    "\n",
    "    The 1999 audi a4 has a 4 cylinder engine.\n",
    "    \n",
    "    > Hint: You will need to concatenate values that already exist in the data with string literals\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d3795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803b6bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg.select(concat(mpg.cyl, lit(\" cylinders\"))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0258671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------+\n",
      "|concat(The , year,  , manufacturer,  , model,  has a , cyl,  cylinder engine)|\n",
      "+-----------------------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine                                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine                             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine                             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine                             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine                             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine                             |\n",
      "|The 1999 audi a6 quattro has a 6 cylinder engine                             |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine                             |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine                             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine                |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine                |\n",
      "+-----------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    concat(\n",
    "        lit('The '), \n",
    "        mpg.year, \n",
    "        lit(' '), \n",
    "        mpg.manufacturer,\n",
    "        lit(' '), \n",
    "        mpg.model, \n",
    "        lit(' has a '), \n",
    "        mpg.cyl, \n",
    "        lit(' cylinder engine'))\n",
    ").show(20,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415bcc2",
   "metadata": {},
   "source": [
    "## b. Transform the trans column so that it only contains either manual or auto.\n",
    "\n",
    "> Hint: Consider spark string methods and `when().otherwise()` chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60e3705",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "from pyspark.sql.functions import when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6582fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.createOrReplaceTempView(\"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9805a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mpg.where(mpg.cyl == 4).where(mpg[\"class\"] == \"subcompact\").show()\n",
    "# vs\n",
    "# mpg.filter(mpg.cyl == 4).where(mpg[\"class\"] == \"subcompact\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d7789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f32665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|     trans|\n",
      "+----------+\n",
      "|  auto(l5)|\n",
      "|manual(m5)|\n",
      "|manual(m6)|\n",
      "|  auto(av)|\n",
      "|  auto(l5)|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT trans\n",
    "FROM mpg\n",
    "\"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04881ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------------------------------------------------------------------+\n",
      "|     trans|CASE WHEN (regexp_extract(trans, ^([a]), 1) = auto) THEN auto ELSE manual END|\n",
      "+----------+-----------------------------------------------------------------------------+\n",
      "|  auto(l5)|                                                                       manual|\n",
      "|manual(m5)|                                                                       manual|\n",
      "|manual(m6)|                                                                       manual|\n",
      "|  auto(av)|                                                                       manual|\n",
      "|  auto(l5)|                                                                       manual|\n",
      "|manual(m5)|                                                                       manual|\n",
      "|  auto(av)|                                                                       manual|\n",
      "|manual(m5)|                                                                       manual|\n",
      "|  auto(l5)|                                                                       manual|\n",
      "|manual(m6)|                                                                       manual|\n",
      "|  auto(s6)|                                                                       manual|\n",
      "|  auto(l5)|                                                                       manual|\n",
      "+----------+-----------------------------------------------------------------------------+\n",
      "only showing top 12 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mpg.select(\n",
    "    'trans',\n",
    "    when(regexp_extract(\"trans\", r\"^([a])\", 1) == \"auto\", \"auto\") \n",
    "    # the problem here goes deeper than the regex. see correct answer below\n",
    "    .otherwise(\"manual\")\n",
    ").show(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee2fcdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------------+-----------+\n",
      "|     trans|regexp_extract|regexp_replace|when + like|\n",
      "+----------+--------------+--------------+-----------+\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(av)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|manual(m5)|        manual|        manual|     manual|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|manual(m6)|        manual|        manual|     manual|\n",
      "|  auto(l5)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(s6)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "|  auto(l4)|          auto|          auto|       auto|\n",
      "+----------+--------------+--------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiple ways to do this\n",
    "mpg.select(\n",
    "    'trans',\n",
    "    regexp_extract(\"trans\", r\"^(\\w+)\", 1).alias(\"regexp_extract\"),\n",
    "    regexp_replace(\"trans\", r\"\\(.+$\", \"\").alias(\"regexp_replace\"),\n",
    "    when(\n",
    "        mpg.trans.like(\"a%\"), \"auto\")\n",
    "    .otherwise(\"manual\").alias(\"when + like\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e426ae2",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "## Exercise 3: \n",
    "\n",
    "Load the `tips` dataset as a spark dataframe.\n",
    "\n",
    "a. What percentage of observations are smokers?\n",
    "> Hint: `.groupBy()` and `.withColumn()` are useful functions here\n",
    "\n",
    "b. Create a column that contains the tip percentage\n",
    "> Hint: `.withColumn()` is useful here\n",
    "\n",
    "c. Calculate the average tip percentage for each combination of sex and smoker.\n",
    "> Hint: Chain additional functions off the answer to part b \n",
    "\n",
    "# ------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e97518cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydataset import data\n",
    "import pydataset\n",
    "tips = spark.createDataFrame(pydataset.data(\"tips\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "793b0774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ada26",
   "metadata": {},
   "source": [
    "### a. What percentage of observations are smokers?\n",
    "> Hint: `.groupBy()` and `.withColumn()` are useful functions here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24521201",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|smoker|count|\n",
      "+------+-----+\n",
      "|    No|  151|\n",
      "|   Yes|   93|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('smoker').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b382fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a55c07c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+\n",
      "|smoker|count|percent|\n",
      "+------+-----+-------+\n",
      "|    No|  151|   62.0|\n",
      "|   Yes|   93|   38.0|\n",
      "+------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.groupBy('smoker').count().withColumn('percent', \n",
    "                                          round((col('count')/tips.count()*100), 0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f1f7557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbc35f",
   "metadata": {},
   "source": [
    "### b. Create a column that contains the tip percentage\n",
    "> Hint: `.withColumn()` is useful here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dd6f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tips.withColumn('tip_percentage', tips.tip/tips.total_bill).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fbf36d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|     tip_percentage|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|0.05944673337257211|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|0.16054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|0.16658733936220846|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2| 0.1397804054054054|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|0.14680764538430255|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|0.18623962040332148|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|0.22805017103762829|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|0.11607142857142858|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|0.13031914893617022|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2| 0.2185385656292287|\n",
      "|     10.27|1.71|  Male|    No|Sun|Dinner|   2| 0.1665043816942551|\n",
      "|     35.26| 5.0|Female|    No|Sun|Dinner|   4|0.14180374361883155|\n",
      "|     15.42|1.57|  Male|    No|Sun|Dinner|   2|0.10181582360570687|\n",
      "|     18.43| 3.0|  Male|    No|Sun|Dinner|   4|0.16277807921866522|\n",
      "|     14.83|3.02|Female|    No|Sun|Dinner|   2|0.20364126770060686|\n",
      "|     21.58|3.92|  Male|    No|Sun|Dinner|   2|0.18164967562557924|\n",
      "|     10.33|1.67|Female|    No|Sun|Dinner|   3| 0.1616650532429816|\n",
      "|     16.29|3.71|  Male|    No|Sun|Dinner|   3|0.22774708410067526|\n",
      "|     16.97| 3.5|Female|    No|Sun|Dinner|   3|0.20624631703005306|\n",
      "|     20.65|3.35|  Male|    No|Sat|Dinner|   3|0.16222760290556903|\n",
      "+----------+----+------+------+---+------+----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.withColumn(\"tip_percentage\", col(\"tip\") / col(\"total_bill\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ce9bd2",
   "metadata": {},
   "source": [
    "### c. Calculate the average tip percentage for each combination of sex and smoker.\n",
    "> Hint: Chain additional functions off the answer to part b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b2eb300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tips.withColumn(\"tip_percentage\", col(\"tip\") / col(\"total_bill\")) \\\n",
    "# .groupby('sex').pivot('smoker').agg(mean('tip_percentage')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b658140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "|   sex|                No|                Yes|\n",
      "+------+------------------+-------------------+\n",
      "|Female|0.1569209707691836|0.18215035269941032|\n",
      "|  Male|0.1606687151291298|0.15277117520248512|\n",
      "+------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tips.withColumn(\"tip_percentage\", col(\"tip\") / col(\"total_bill\")). \\\n",
    "groupby(\"sex\").pivot(\"smoker\").agg(mean(\"tip_percentage\")).show()\n",
    "# tip % for sex and smoker status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23e346",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------\n",
    "## Exercise 4:\n",
    "\n",
    "Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "- Which month has the most rain, on average?\n",
    "- Which year was the windiest?\n",
    "- What is the most frequent type of weather in January?\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6353121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9c7ab1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape:  1461  x  6\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame shape: \", weather.count(), \" x \", len(weather.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3443cc1a",
   "metadata": {},
   "source": [
    "### - Convert the temperatures to fahrenheit.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92fb1f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+------------------+------------------+\n",
      "|      date|precipitation|wind|weather|temp_max_farenheit|temp_min_farenheit|\n",
      "+----------+-------------+----+-------+------------------+------------------+\n",
      "|2012-01-01|          0.0| 4.7|drizzle|             55.04|              41.0|\n",
      "|2012-01-02|         10.9| 4.5|   rain|             51.08|             37.04|\n",
      "|2012-01-03|          0.8| 2.3|   rain|             53.06|             44.96|\n",
      "+----------+-------------+----+-------+------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.withColumn('temp_max_farenheit', ((weather.temp_max * 9)/5 +32))\n",
    ".withColumn('temp_min_farenheit', ((weather.temp_min * 9)/5 +32))\n",
    ".drop(weather.temp_max)\n",
    ".drop(weather.temp_min)    \n",
    ".show(3)\n",
    ")\n",
    "\n",
    "# you could have named the new column the same name, overwriting it if you had preferred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b2dd4",
   "metadata": {},
   "source": [
    "### - Which month has the most rain, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cbe19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month, year, quarter\n",
    "from pyspark.sql.functions import asc, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "862bbddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg.createOrReplaceTempView(\"weather\")\n",
    "# the idea here was to register for sql usage. didn't follow throough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad6b3677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|       avg_precip|\n",
      "+-----+-----------------+\n",
      "|   11|5.354166666666667|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather\n",
    ".withColumn('month',month('date'))\n",
    ".groupBy('month')\n",
    ".agg(expr(\"MEAN(precipitation) AS avg_precip\"))\n",
    ".sort(desc('avg_precip')).limit(1)\n",
    "# .select('avg_precip')\n",
    "# .orderBy(F.desc('avg_precip')).limit(1)\n",
    ".show()\n",
    ")\n",
    "\n",
    "# finally got it\n",
    "# ACTUALLY.... i got the average daily precip, not monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a162efb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(month=11, avg_monthly_rain=160.625)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adam solution:\n",
    "\n",
    "row = (\n",
    "weather\n",
    ".withColumn('month',month('date'))\n",
    ".withColumn('year',year('date'))\n",
    ".groupBy('month','year')\n",
    ".agg(sum(\"precipitation\").alias('total_monthly_precip'))\n",
    ".groupBy('month')\n",
    ".agg(mean('total_monthly_precip').alias('avg_monthly_rain'))\n",
    ".sort(col('avg_monthly_rain').desc())\n",
    "# .select('avg_precip')\n",
    "# .orderBy(F.desc('avg_precip')).limit(1)\n",
    ".first()\n",
    ")\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7bebe2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.625"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.avg_monthly_rain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f8c440",
   "metadata": {},
   "source": [
    "### - Which year was the windiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e03c3af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         avg(wind)|\n",
      "+------------------+\n",
      "|3.2411362080766604|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(mean('wind')).show()\n",
    "# overall average wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cb05be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+\n",
      "|year|         avg_wind|\n",
      "+----+-----------------+\n",
      "|2012|3.400819672131148|\n",
      "+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather\n",
    ".withColumn('year',year('date'))\n",
    ".groupBy('year')\n",
    ".agg(mean('wind').alias('avg_wind'))\n",
    "# .agg(expr(\"max(wind)\"))\n",
    ".sort(desc('avg_wind')).limit(1)\n",
    "# .select('avg_precip')\n",
    "# .orderBy(F.desc('avg_precip')).limit(1)\n",
    ".show()\n",
    ")\n",
    "\n",
    "\n",
    "# nicely done\n",
    "# NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cadc3d34",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'total_wind' given input columns: [total_winds, year];\n'Sort ['total_wind ASC NULLS FIRST], true\n+- Aggregate [year#1411], [year#1411, sum(wind#457) AS total_winds#1427]\n   +- Project [date#453, precipitation#454, temp_max#455, temp_min#456, wind#457, weather#458, year(cast(date#453 as date)) AS year#1411]\n      +- LogicalRDD [date#453, precipitation#454, temp_max#455, temp_min#456, wind#457, weather#458], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-d35ab7488e87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m (\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mweather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(self, *cols, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Bob'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \"\"\"\n\u001b[0;32m-> 1421\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sort_cols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'total_wind' given input columns: [total_winds, year];\n'Sort ['total_wind ASC NULLS FIRST], true\n+- Aggregate [year#1411], [year#1411, sum(wind#457) AS total_winds#1427]\n   +- Project [date#453, precipitation#454, temp_max#455, temp_min#456, wind#457, weather#458, year(cast(date#453 as date)) AS year#1411]\n      +- LogicalRDD [date#453, precipitation#454, temp_max#455, temp_min#456, wind#457, weather#458], false\n"
     ]
    }
   ],
   "source": [
    "# adam:\n",
    "\n",
    "(\n",
    "weather\n",
    ".withColumn('year',year('date'))\n",
    ".groupBy('year')\n",
    ".agg(sum('wind').alias('total_winds'))\n",
    "# .agg(expr(\"max(wind)\"))\n",
    ".sort(col('total_wind')).desc()\n",
    "# .select('avg_precip')\n",
    "# .orderBy(F.desc('avg_precip')).limit(1)\n",
    ".head()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90333883",
   "metadata": {},
   "source": [
    "### - What is the most frequent type of weather in January?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "527131a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02662726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.withColumn(\n",
    "    \"temp_avg\", expr(\"ROUND(temp_min + temp_max) / 2\")\n",
    ").drop(\"temp_max\", \"temp_min\")\n",
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cbb4912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|weather|count(weather)|\n",
      "+-------+--------------+\n",
      "|   rain|            16|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(month(\"date\") == 1)\n",
    ".filter(year(\"date\") == 2013)\n",
    ".groupBy(\"weather\")\n",
    ".agg(count(\"weather\"))\n",
    ".sort(desc('count(weather)')).limit(1)\n",
    ".show()\n",
    ")\n",
    "\n",
    "\n",
    "# good work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e146d",
   "metadata": {},
   "source": [
    "### - What is the average high and low temperature on sunny days in July in 2013 and 2014?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5b03869f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|     avg(temp_max)|    avg(temp_min)|\n",
      "+------------------+-----------------+\n",
      "|26.828846153846158|14.18269230769231|\n",
      "+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(col(\"weather\") == 'sun')\n",
    ".filter(month(\"date\") == 7)\n",
    ".filter(\n",
    "    ((year(\"date\") == 2014) \n",
    "      | (year('date')==2013))\n",
    "        )\n",
    ".agg(mean(\"temp_max\"),mean('temp_min'))\n",
    "# .select('temp_max', 'temp_min')\n",
    ".show()\n",
    ")\n",
    "\n",
    "# i think this is it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6efcb243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.276"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(26.82 * 9)/5 + 32\n",
    "# just checking, i got it but in celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5303f",
   "metadata": {},
   "source": [
    "### - What percentage of days were rainy in q3 of 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c91221f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9114c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            whatever|\n",
      "+--------------------+\n",
      "|0.021739130434782608|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather.filter(col(\"weather\") == 'rain')\n",
    ".filter(year(\"date\") == 2015)\n",
    ".filter(\n",
    "    quarter(\"date\") == 3)\n",
    "    .agg(count('weather')/weather.filter(quarter('date')==3)\n",
    "         .filter(year('date')==2015).count())\n",
    "    \n",
    "    # .show()\n",
    ").select(col('(count(weather) / 92)').alias('whatever')).show()\n",
    "\n",
    "# good work, would like to alias it though...and...adam helped me get it\n",
    "# notice how we have to define the query (we removed the .show) and re-select the resulting column\n",
    "# (that was the (count(weather))), and then alias it and show it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f493472",
   "metadata": {},
   "source": [
    "- i also like adam's solution, where he created a 'rain' column with 1 or 0 value, ad got the mean of that\n",
    "- `.select(when(col('weather') == 'rain', 1).otherwise(0).alias('rain'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18569b1",
   "metadata": {},
   "source": [
    "### - For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20e205fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28e482c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f98aa1c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------------------+\n",
      "|year(date)|count|percent_days_w_rain|\n",
      "+----------+-----+-------------------+\n",
      "|      2012|  177| 0.4849315068493151|\n",
      "|      2013|  152|0.41643835616438357|\n",
      "|      2014|  150|  0.410958904109589|\n",
      "|      2015|  144|0.39452054794520547|\n",
      "+----------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "weather\n",
    ".filter(col(\"precipitation\") > 0)\n",
    ".groupBy(year('date')).count()\n",
    "# .withColumn('year', year('date'))\n",
    "# .pivot(year('year'))\n",
    ".withColumn('percent_days_w_rain',(col('count')/365))\n",
    ".show()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f74fbc54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ###############################\n",
    "# #### why can't i get .pivot() to work?\n",
    "# ######################################\n",
    "\n",
    "\n",
    "\n",
    "# (\n",
    "# weather.withColumn('percent_days_w_rain',(weather.filter(((col('precipitation')>0)\n",
    "#                                                         .groupBy(year('date')).count())\n",
    "#                                                         /col('count')/365)))\n",
    "#     .groupBy('count')\n",
    "#     .pivot(year('date'))\n",
    "#     .agg('percent_days_w_rain')\n",
    "#     .show()\n",
    "# )\n",
    "\n",
    "# #.groupBy followed immediately by the pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbec3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.withColumn(\"tip_percentage\", col(\"tip\") / col(\"total_bill\")). \\\n",
    "groupby(\"sex\").pivot(\"smoker\").agg(mean(\"tip_percentage\")).show()\n",
    "# tip % for sex and smoker status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e4f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
